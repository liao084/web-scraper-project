# 微店订单自动化导出工具 (V3.1 - 高性能API采集器重构版)

本项目是一个使用Python实现的、工业级的自动化工具。它通过现代异步技术栈，实现了对微店订单数据的高速采集、高并发截图处理，并将最终结果导出为图文并茂的、格式精美的Excel报告。

V3版本奠定了项目优秀的解耦架构，而 **V3.1 版本则是一次针对“采集”核心的“心脏搭桥手术”**。它用一个全新的、基于直接API请求的高性能采集器，彻底解决了 V3 在大规模数据采集场景下遇到的性能瓶颈，将工具的性能、健壮性和抗封锁能力提升到了全新的高度。

---

## ✨ V3.1 版本有什么新特性？

V3.1 的核心升级聚焦于项目的“生产者”——数据采集器，旨在解决 V3 版本的一个关键瓶颈：

*   **问题背景**: 原 V3 采集器基于 Playwright 模拟浏览器滚动加载，在处理大规模订单（如超过1000页）时，页面 DOM 树会变得异常庞大，导致浏览器实例不堪重负，后期采集性能严重衰减（从 0.5秒/页 降至 4-6秒/页），甚至有崩溃风险。

*   **V3.1 的解决方案**: 我们用一个全新的、基于直接API请求的高性能采集器 (`collector_curl_cffi.py`) 替换了原有的 Playwright 采集器。这一变革带来了：

    1.  **极致且恒定的性能**:
        *   彻底摆脱了浏览器的性能束缚，采集速度不再随数据量的增加而衰减。
        *   实测性能高达 **1200秒 完成 22000条 订单** 的采集，平均 **~0.05秒/订单**，性能实现了数量级的飞跃。

    2.  **更低的资源占用**:
        *   纯粹的异步网络I/O操作，CPU和内存占用相比启动一个完整的浏览器实例大幅降低。

    3.  **先进的抗封锁策略**:
        *   **`curl_cffi` 深度伪装**: 利用其模拟真实浏览器 TLS/JA3 指纹的能力，从网络协议层绕过WAF的基础机器人检测。
        *   **动态指纹池**: 每次请求都会从一个包含多种浏览器版本的指纹池中随机选择一个进行伪装，使得客户端特征难以被追踪。
        *   **企业级代理集成**: 完美集成高匿住宅代理池，分散请求来源。
        *   **健壮的重试机制**: 内置自动重试逻辑，能从容应对瞬时的网络波动或服务器错误。

    4.  **配置与代码分离**:
        *   所有敏感信息（Cookie、代理凭证）均通过 `.env` 文件进行管理，代码更干净、更安全，遵循了十二要素应用的最佳实践。

---

## 🛠️ 技术栈 (V3.1 更新)

- **核心框架**: Python 3.12+
- **并发模型**: Asyncio
- **数据采集**:
    - **HTTP客户端**: `curl_cffi` (用于模拟浏览器指纹)
    - **代理集成**: Smartproxy (或任何其他住宅代理)
    - **配置管理**: `python-dotenv`
- **浏览器自动化 (截图阶段)**: Playwright (Async API)
- **数据库**: aiosqlite (SQLite的异步驱动)
- **数据处理与导出**: Pandas, XlsxWriter
- **图像处理**: Pillow

---

## 🚀 快速开始

### 1. 环境准备

强烈建议在Python虚拟环境中安装本项目。

```bash
# 创建并激活虚拟环境 (macOS/Linux)
python3 -m venv .venv
source .venv/bin/activate

# 创建并激活虚拟环境 (Windows)
python -m venv .venv
.venv\Scripts\activate

# 安装所有依赖 (请确保 requirements.txt 已更新)
pip install -r requirements.txt
```
### 2. 创建并配置 .env 文件
V3.1 将所有配置项移至根目录下的 `.env` 文件。请在项目目录根目录创建一个名为 `.env` 的文件，并填入以下内容：

```ini
# .env.example

# --- Smartproxy 代理配置 ---
# 请替换为您从Smartproxy中获取的最新的用户名和密码
SMARTPROXY_USERNAME=your_proxy_username
SMARTPROXY_PASSWORD=your_proxy_password
SMARTPROXY_ENDPOINT=proxy.smartproxy.net
SMARTPROXY_PORT=10000

# --- 微博 Cookie ---
# 请将从微博获取到的最新Cookie，完整的Cookie粘贴在这里
MY_COOKIE=""
```

## 3. 完整执行流程 (三步走)
请严格按照以下顺序，依次执行三个独立的脚本。

---
### 第1步：运行高匿名采集器 (`collector_curl_cffi.py`)

此脚本负责通过高匿的API请求，将订单元数据抓取到本地的 tasks.db 数据库文件中。

*   **配置**：
    *   **1**.确保根目录下的 `.env` 文件已正确填写 `SMARTPROXY_*` 和 `MY_COOKIE`。
    *   **2**.(可选) 打开 `collector_curl_cffi.py`，在文件顶部的“核心策略与性能调优参数”区域，根据需要调整 `PAGES_TO_FETCH` (抓取页数) 和 `CONCURRENT_REQUESTS` (并发数)。

*   **产出**：在项目根目录下生成一个 `tasks.db` 文件。
---

### 第2步：运行并行截图器 (`screenshotter_async.py`)

此脚本将从 tasks.db 中读取任务，并启动多个并发浏览器实例进行截图。

*   **配置**：
    *   **1**.此脚本会自动从 `.env` 文件中读取 `MY_COOKIE`，无需手动配置。
    *   **2**.(可选) 打开 `screenshotter_async.py`，根据您的电脑性能，调整 `WORKER_COUNT` (并发数)。

*   **产出**：在 `screenshots` 文件夹中生成大量截图，并更新 `tasks.db` 文件中的任务状态。
---

### 第3步：运行报告生成器 (`exportor_async.py`)

此脚本负责读取数据库中所有已完成的任务，生成最终的Excel文件。

*   **配置**：(可选) 打开 `exportor_async.py`，修改 `OUTPUT_FILENAME` 变量以自定义输出文件名。

*   **产出**：在项目根目录下生成最终的 `.xlsx` 报告文件。
---

## 架构设计概览 (`V3.1`)

V3.1 沿用了 V3 成功的、基于异步事件驱动的**生产者-消费者**模型，并对生产者进行了核能升级。

*   **`collector_curl_cffi.py`(超级生产者):**
    *   不再依赖笨重的浏览器，而是作为一个轻量级、高匿名的API请求集群。它主动构造并发送高度伪装的网络请求，以惊人的速度生产“任务”（订单数据），并将其存入“仓库” (tasks.db)。

*   **`screenshotter_async.py` (异步消费者集群):**
    *   (与V3版本职责相同) 作为高效的消费者，它从“仓库”中领取任务，并利用 Playwright 的 BrowserContext 池，并行地完成截图“加工”工作。

*   **`exportor_async.py` (报告员):**
    *   (与V3版本职责相同) 在所有工作完成后，对“仓库”中所有“已完成”的成品进行盘点，并生成一份精美的报告。