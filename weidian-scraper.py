# scraper.py
# æœ€ç»ˆäº¤ä»˜ç‰ˆ - JSONé«˜é€Ÿé‡‡é›† + ç²¾å‡†è£å‰ª/æ ¼å¼åŒ–æˆªå›¾ + å®Œç¾Excelå¯¼å‡º
import json
import time
import gzip
import os
import io
from typing import List

import pandas as pd
from PIL import Image, ImageChops
from seleniumwire import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

from common import OrderData


class WeidianScraper:
    """
    å°è£…äº†æ‰€æœ‰å¾®åº—è®¢å•çˆ¬å–å’Œå¤„ç†é€»è¾‘çš„ä¸»ç±»ï¼ˆæœ€ç»ˆäº¤ä»˜ç‰ˆï¼‰ã€‚
    """

    def __init__(self, headless: bool = False):
        print("æ­£åœ¨åˆå§‹åŒ–selenium-wireæµè§ˆå™¨é©±åŠ¨...")
        options = webdriver.ChromeOptions()
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_argument("--window-size=1200,1080")
        if headless:
            options.add_argument("--headless")
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)
        self.wait = WebDriverWait(self.driver, 30)
        print("æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å®Œæˆã€‚")

    def login_with_cookie(self, cookie_string: str):
        print("æ­£åœ¨ä½¿ç”¨Cookieè¿›è¡Œç™»å½•...")
        self.driver.get("https://weidian.com/")
        time.sleep(2)
        self.driver.delete_all_cookies()
        for cookie_item in cookie_string.split(';'):
            if '=' in cookie_item:
                name, value = cookie_item.strip().split('=', 1)
                self.driver.add_cookie({'name': name, 'value': value, 'domain': '.weidian.com'})
        print("Cookieæ³¨å…¥å®Œæˆã€‚")

    def _parse_response(self, request) -> List[OrderData]:
        # ... _parse_response å‡½æ•°ä¿æŒä¸å˜ ...
        raw_body = request.response.body
        if 'gzip' in request.response.headers.get('Content-Encoding', ''):
            decompressed_body = gzip.decompress(raw_body)
        else:
            decompressed_body = raw_body
        response_json = json.loads(decompressed_body.decode('utf-8'))
        orders = []
        if "result" in response_json and "listRespDTOList" in response_json["result"]:
            for order_dict in response_json["result"]["listRespDTOList"]:
                final_price_str = order_dict.get("modified_total_price") or order_dict.get("total_price", "0.0")
                sub_order = order_dict.get("sub_orders", [{}])[0]
                order = OrderData(
                    order_id=order_dict.get("order_id"),
                    item_title=sub_order.get("item_title"),
                    item_sku_title=sub_order.get("item_sku_title"),
                    order_status=order_dict.get("status_desc"),
                    total_price=str(final_price_str),
                    creation_time=order_dict.get("add_time"),
                    payment_time=order_dict.get("pay_time"),
                    shipping_time=order_dict.get("express_time"),
                    order_detail_url=order_dict.get("order_detail_url"),
                )
                orders.append(order)
        return orders

    def _trim_image(self, image: Image.Image) -> Image.Image:
        """ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºè‡ªåŠ¨è£å‰ªå›¾ç‰‡çš„ç©ºç™½è¾¹ç¼˜"""
        bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))
        diff = ImageChops.difference(image, bg)
        diff = ImageChops.add(diff, diff, 2.0, -100)
        bbox = diff.getbbox()
        if bbox:
            return image.crop(bbox)
        return image

    def take_screenshots(self, orders_data: List[OrderData]):
        print(f"\n--- Phase 3: å¼€å§‹æ‰§è¡Œæˆªå›¾ä¸ç²¾åŠ å·¥ä»»åŠ¡ ---")
        if not os.path.exists("screenshots"):
            os.makedirs("screenshots")

        main_container_xpath = '//*[@id="detail"]'
        # æ ¹æ®æ‚¨çš„æŒ‡ç¤ºï¼Œå†…å®¹åŒºçš„ç›®æ ‡å®½åº¦ä¸º640px
        TARGET_WIDTH = 640

        for i, order in enumerate(orders_data):
            print(f"  > æ­£åœ¨ä¸ºè®¢å• {i + 1}/{len(orders_data)} (ID: {order.order_id}) æˆªå›¾...")
            if not order.order_detail_url:
                print("    - âŒ ç¼ºå°‘è¯¦æƒ…é¡µURLï¼Œè·³è¿‡ã€‚")
                continue

            try:
                self.driver.get(order.order_detail_url)
                main_container = self.wait.until(EC.visibility_of_element_located((By.XPATH, main_container_xpath)))
                self.driver.execute_script("document.body.style.zoom='80%'")
                time.sleep(1.5)  # å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿ç¼©æ”¾å’Œæ¸²æŸ“å®Œæˆ

                # 1. æˆªå–çˆ¶å®¹å™¨
                base_screenshot_png = main_container.screenshot_as_png
                base_image = Image.open(io.BytesIO(base_screenshot_png))

                # 2. ç²¾ç¡®è£å‰ªå·¦ä¾§å’Œå³ä¾§ç©ºç™½
                # æˆ‘ä»¬å‡è®¾å†…å®¹æ˜¯å·¦å¯¹é½çš„ï¼Œæ‰€ä»¥åªè£å‰ªå³è¾¹
                final_image = base_image.crop((0, 0, TARGET_WIDTH, base_image.height))

                # 3. è‡ªåŠ¨è£å‰ªé¡¶éƒ¨å’Œåº•éƒ¨çš„ç©ºç™½
                final_image = self._trim_image(final_image)

                # 4. ä¿å­˜æœ€ç»ˆå¤„ç†è¿‡çš„å›¾ç‰‡
                screenshot_path = os.path.join("screenshots", f"{order.order_id}.png")
                final_image.save(screenshot_path)
                order.screenshot_path = screenshot_path
                print(f"    - âœ… æˆªå›¾ç²¾åŠ å·¥æˆåŠŸ: {screenshot_path}")

            except Exception as e:
                print(f"    - âŒ æˆªå›¾å¤±è´¥: {e}")

    def save_to_excel(self, all_orders_data: List[OrderData], filename="å¾®åº—è®¢å•å¯¼å‡º.xlsx"):
        """
        ã€å¤§é“è‡³ç®€ç‰ˆã€‘ç”Ÿæˆæ ¼å¼ç»Ÿä¸€çš„ExcelæŠ¥å‘Šï¼Œå°†æœ€ç»ˆé€‚é…å·¥ä½œäº¤ç»™WPSã€‚
        """
        print(f"\n--- Phase 4: å¼€å§‹ç”Ÿæˆæ ¼å¼ç»Ÿä¸€çš„ExcelæŠ¥å‘Š ---")
        if not all_orders_data: return

        df = pd.DataFrame([{
            'è®¢å•å·': order.order_id,
            'å•†å“åç§°': order.item_title,
            'å•†å“è§„æ ¼': order.item_sku_title,
            'è®¢å•çŠ¶æ€': order.order_status,
            'å®ä»˜é‡‘é¢': order.total_price,
            'ä¸‹å•æ—¶é—´': order.creation_time,
            'ä»˜æ¬¾æ—¶é—´': order.payment_time,
        } for order in all_orders_data])

        writer = pd.ExcelWriter(filename, engine='xlsxwriter')
        df.to_excel(writer, sheet_name='è®¢å•è¯¦æƒ…', index=False)
        workbook = writer.book
        worksheet = writer.sheets['è®¢å•è¯¦æƒ…']

        # 1. åˆ›å»ºå¹¶åº”ç”¨æ–‡æœ¬æ ¼å¼
        cell_format = workbook.add_format({'valign': 'vcenter', 'align': 'left'})
        worksheet.set_column('A:G', 22, cell_format)
        worksheet.write('H1', 'è®¢å•æˆªå›¾')

        # ====================ã€ æœ€ç»ˆæ ¸å¿ƒä¿®æ­£ ã€‘====================

        # 2. åªè®¾ç½®ä¸€ä¸ªå›ºå®šçš„ã€è¶³å¤Ÿå®½çš„åˆ—å®½
        worksheet.set_column('H:H', 95)

        # 3. éå†æ¯ä¸€è¡Œï¼Œåªè®¾ç½®ä¸€ä¸ªç»Ÿä¸€çš„ã€è¶³å¤Ÿé«˜çš„é»˜è®¤è¡Œé«˜
        for index, order in enumerate(all_orders_data):
            row_num = index + 1
            worksheet.set_row(row_num, 400)  # ç»™äºˆä¸€ä¸ªè¶³å¤Ÿå¤§çš„åˆå§‹è¡Œé«˜

            if order.screenshot_path and os.path.exists(order.screenshot_path):
                # æ’å…¥å›¾ç‰‡æ—¶ä¸å†å…³å¿ƒå°ºå¯¸ï¼Œè®©å®ƒä»¥åŸå§‹æ¯”ä¾‹æ”¾å…¥
                worksheet.insert_image(
                    row_num, 7,  # Håˆ—
                    order.screenshot_path,
                    {'object_position': 1}  # ä¾ç„¶ä¿æŒé”šå®š
                )
        # =============================================================

        writer.close()
        print(f"âœ… Excelæ–‡ä»¶ '{filename}' å†™å…¥æˆåŠŸï¼è¯·æ‰“å¼€æ–‡ä»¶åè¿›è¡Œæ‰¹é‡è½¬æ¢ã€‚")

    def run(self, clicks_to_perform: int):
        # ... run å‡½æ•°ä¿æŒä¸å˜ ...
        self.login_with_cookie(MY_COOKIE)
        discovered_orders = []
        start_url = "https://weidian.com/user/order/list.php?type=2"
        self.driver.get(start_url)
        try:
            all_tab_xpath = '//*[@id="app"]/div[2]/div[2]/ul/li[1]/span'
            all_tab_button = self.wait.until(EC.element_to_be_clickable((By.XPATH, all_tab_xpath)))
            del self.driver.requests
            all_tab_button.click()
            initial_request = self.wait.until(lambda d: d.wait_for_request(r'tradeview/buyer.order.list'))
            initial_orders = self._parse_response(initial_request)
            discovered_orders.extend(initial_orders)
            for i in range(clicks_to_perform):
                print(f"\n--- æ­£åœ¨åŠ è½½ç¬¬ {i + 2} é¡µ... ---")
                button_selector = (By.CSS_SELECTOR, "div.order_add_list .more_span")
                load_more_button = self.wait.until(EC.element_to_be_clickable((button_selector)))
                self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", load_more_button)
                time.sleep(1)
                del self.driver.requests
                self.driver.execute_script("arguments[0].click();", load_more_button)
                next_page_request = self.wait.until(lambda d: d.wait_for_request(r'tradeview/buyer.order.list/1.1'))
                next_page_orders = self._parse_response(next_page_request)
                discovered_orders.extend(next_page_orders)
        except TimeoutException:
            print(f"\nâœ… æ‰€æœ‰è®¢å•é¡µé¢å·²åŠ è½½å®Œæ¯•ã€‚")
        print(f"\n--- å¿«é€Ÿå‘ç°é˜¶æ®µå®Œæˆï¼Œå…±æ‰¾åˆ° {len(discovered_orders)} æ¡è®¢å•è®°å½•ã€‚---")

        self.take_screenshots(discovered_orders)
        self.save_to_excel(discovered_orders)
        print("\nğŸ‰ğŸ‰ğŸ‰ é¡¹ç›®æ‰§è¡Œå®Œæ¯•ï¼ ğŸ‰ğŸ‰ğŸ‰")


# --- ä¸»å…¥å£ (Main Entry Point) ---
if __name__ == "__main__":
    # 1. åœ¨ç¨‹åºå¼€å§‹æ—¶è®°å½•æ—¶é—´
    start_time = time.time()

    MY_COOKIE = ("__spider__visitorid=2ef09da5a6200925; smart_login_type=0; hi_dxh=; hold=; cn_merchant=; token=; isLogin=; loginUserType=; loginUserSource=; WD_b_id=; WD_b_wduss=; WD_b_country=; WD_b_tele=; WD_s_id=; WD_s_tele=; WD_s_wduss=; WD_seller=; is_login=true; login_type=LOGIN_USER_TYPE_MASTER; login_source=LOGIN_USER_SOURCE_MASTER; uid=1914883825; duid=1914883825; sid=1798256885; wdtoken=58ed060c; __spider__sessionid=2584a22f42a4db8a; login_token=_EwWqqVIQD0u47mFa1wCctnrLcWiA3ZQaBijugH_WeK9ovMUam2aWW1xg1j8s9jLx25qxxOGDQPyK2ZR1QKKtoYFtppFGSj2MXLO9shg_IsiM0vFPNszXRVyLhYcC9yY2V_slrb8-HglH4CsvQRGQUrYBAJeGp7CYAdDL5Bkdvxd_Yj1x0vVr9QEt0Tqgh18433yDSEoGB-y3L5vAKKLVDDcyWDwqlBk1lhddJKxnecFuUx5g6VnlhG0zDoHL7SIlOUPrT3ql; v-components/clean-up-advert@private_domain=1736676582; v-components/clean-up-advert@wx_app=1736676582")  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„æœ‰æ•ˆCookie
    CLICKS_TO_PERFORM = 10  # å…ˆè®¾ç½®ä¸º0ï¼Œæµ‹è¯•10æ¡

    scraper = WeidianScraper()
    try:
        scraper.run(clicks_to_perform=CLICKS_TO_PERFORM)
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œæ—¶é‡åˆ°è‡´å‘½é”™è¯¯: {e}")
    finally:
        print("ç¨‹åºè¿è¡Œç»“æŸï¼ŒæŒ‰å›è½¦é”®é€€å‡º...")

        # 2. è®¡ç®—å¹¶æ‰“å°æ€»è€—æ—¶
        end_time = time.time()
        duration = end_time - start_time
        print(f"ç¨‹åºæ€»è€—æ—¶: {duration:.2f} ç§’")

        input()
        scraper.driver.quit()